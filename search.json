[
  {
    "objectID": "pages/tidytuesday.html",
    "href": "pages/tidytuesday.html",
    "title": "Tidytuesday",
    "section": "",
    "text": "Le Tidytuesday, c’est un évènement qui a lieu chaque semaine, où la communauté R se challenge pour créer des visualisations à partir d’un nouveau jeu de données, publié tous les mardis. \n\n\n\n\n\n\n\n\n\n\n\n\nCranes\n\n\nObservations de grues en Suède\n\n\n\nFélix Marchais\n\n\nOct 7, 2025\n\n\n\n\n\n\n\n\n\n\n\nFrogs\n\n\nObservations des grenouilles en Australie - 2025-09-02\n\n\n\nFélix Marchais\n\n\nSep 14, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/tidytuesday/20250930/cranes.html",
    "href": "pages/tidytuesday/20250930/cranes.html",
    "title": "Cranes",
    "section": "",
    "text": "Cette semaine, le jeu de données porte sur l’observation de grues (les oiseaux) au lac Hornborgasjön, en Suède, entre 1994 et 2025.\nL’objectif de ma visualisation est de mettre en évidence la saisonnalité des observations ainsi que leur augmentation au fil des ans. L’année la plus récente (2025) est indiquée en blanc.\nLe code pour obtenir ce graphe :\n\n##### SETUP ######\nlibrary(tidytuesdayR)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(grid)\n\n# For months names\nSys.setlocale(\"LC_TIME\", \"English\")\n\n\n\n\n\n##### DATA #####\ntuesdata &lt;- tidytuesdayR::tt_load('2025-09-30')\ncranes &lt;- tuesdata$cranes\n\n\n##### CLEANING ######\nclean_cranes &lt;- cranes %&gt;%\n  mutate(\n    year = year(date),\n    date = as.Date(sprintf(\"2025-%02d-%02d\", month(date), day(date))),\n    month_day = format(date, \"%b-%d\")\n  ) %&gt;%\n  filter(!is.na(date) & !is.na(observations))\n\n# determine the most recent year to highlight it\nlatest_year &lt;- max(clean_cranes$year, na.rm = TRUE)\n\n# Get the \"next\" 10.000 after maximal observation number\ny_limit &lt;- ((max(clean_cranes$observations, na.rm = TRUE) %/% 10000) + 1) * 10000\n\n\n\n\n#####PLOT #####\nclean_cranes %&gt;%\n  ggplot(aes(x = date, y = observations, group = factor(year), color = year)) +\n\n  # light, semi-transparent lines per year\n  geom_line(alpha = 0.35, linewidth = 0.6) +\n\n  # points sized by observation count (smaller range so they don't dominate)\n  geom_point(aes(size = observations), alpha = 0.6, show.legend = FALSE) +\n  scale_size(range = c(0.8, 3.5)) +\n\n  # highlight the most recent year with a bold, bright line and points on top\n  geom_line(\n    data = filter(clean_cranes, year == latest_year),\n    aes(x = date, y = observations, group = factor(year)),\n    color = \"#FFFFFF\",\n    size = 1.2,\n    inherit.aes = FALSE\n  ) +\n  geom_point(\n    data = filter(clean_cranes, year == latest_year),\n    aes(x = date, y = observations),\n    color = \"#FFFFFF\",\n    size = 2,\n    inherit.aes = FALSE\n  ) +\n\n  # continuous color gradient for the year variable using the viridis-like ramp\n   scale_color_viridis_c(guide = guide_colorbar(title = \"Year\", barwidth = unit(6, \"cm\"))) +\n\n  # radial (y) axis - keep the scale available for plotting but don't show the default radial text\n  scale_y_continuous(\n    limits = c(0, y_limit),\n    expand = c(0, 0),\n    breaks = c(0,10000,20000),\n    labels = c(\"0\",\"10k\",\"20k\")\n  ) +\n\n  # show months around the circle\n  scale_x_date(\n    breaks = seq(as.Date(\"2025-01-01\"), as.Date(\"2025-12-01\"), by = \"1 month\"),\n    labels = function(x) format(x, \"%b\"),\n    limits = c(as.Date(\"2025-01-01\"), as.Date(\"2025-12-31\"))\n  ) +\n\n  # polar coordinates with January at top\n  coord_polar(start = -pi/2) +\n\n  # labels\n  labs(\n    title = \"Annual Pattern of Crane Observations\",\n    subtitle = \"Each year mapped onto a single calendar\",\n    caption = \"Data: Tidytuesday | Viz: @fmarchais\",\n    x = NULL,\n    y = NULL\n  ) +\n\n  # revert the earlier radial-label tweak (remove visible radial labels in the margin)\n  theme(\n    panel.background = element_rect(fill = \"#0f1115\", colour = NA),\n    plot.background = element_rect(fill = \"#0f1115\", colour = NA),\n    legend.background = element_rect(fill = \"#0f1115\", colour = NA),\n    legend.key = element_rect(fill = NA, colour = NA),\n    text = element_text(color = \"white\"),\n    plot.title = element_text(size = 12, face = \"bold\", color = \"white\"),\n    plot.subtitle = element_text(size = 9, color = \"grey90\"),\n    plot.caption = element_text(size = 9, color = \"grey70\"),\n\n    # make y & x axis more visible\n    axis.text.y = element_text(color = \"white\", size = 10, margin = margin(r = 6), hjust = 0.5),\n    axis.ticks.y = element_line(color = \"white\", size = 0.5),\n    axis.ticks.length = unit(3, \"pt\"),\n    axis.text.x = element_text(color = \"grey95\", size = 11),\n\n    # remove the \"net\" in the background (radial grid)\n    panel.grid.major.y = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    \n    legend.position = \"bottom\"\n  )\n\n\n# ggsave(filename = \"my_plot.png\", dpi = \"retina\")"
  },
  {
    "objectID": "pages/projets.html",
    "href": "pages/projets.html",
    "title": "Projets",
    "section": "",
    "text": "Ci-dessous vous pourrez retrouver des outils développés pour des projets professionnels ou personnels. \n\n\n\n\n\n\nCautionCette section est encore en travaux !\n\n\n\nPlus de projets seront bientôt publiés ici\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGestionnaire_projets\n\n\nUn tableau de bord pour les chefs de projets\n\n\n\nFélix Marchais\n\n\nSep 15, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/projets/Gestionnaire_projets.html",
    "href": "pages/projets/Gestionnaire_projets.html",
    "title": "Gestionnaire_projets",
    "section": "",
    "text": "Cette application Shiny a été créée comme un tableau de bord permettant à un chef de projet de suivre l’avancée de différentes études. A partir d’un jeu de données fictif chargé dans l’application, il est possible de suivre le nombre et le détail des projets, ainsi que le calendrier de chaque projet et la charge de travail à venir.\nL’application est disponible ici"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue",
    "section": "",
    "text": "CautionCe blog est encore en travaux !\n\n\n\nVous verrez bientôt ma tête ici\n\n\nDéveloppeur R et Data Manager de données cliniques \nDiplômé d’un Master 2 de Biologie - Physiopathologie & Recherche Clinique \nJe me suis spécialisé dans la programmation en R pour des missions de traitement de données de santé, visualisation et automatisation de process. \nDans ce blog, vous pourrez retrouver plus de détails sur mon profil, découvrir les différents usages de R et mes différents projets"
  },
  {
    "objectID": "pages/profil.html",
    "href": "pages/profil.html",
    "title": "Profil",
    "section": "",
    "text": "A propos de moi\nIssu d’un parcours en Biologie et Recherche Clinique, je me suis rapidement dirigé vers le traitement de données de santé à la fin de l’année de Master 1, en me formant en autodidacte au langage R.\nMon parcours professionnel m’a amené à travailler dans le milieu du Dispositif Médical (DM) en orthopédie, puis dans les études de vie réelle (RWD) en cancérologie.\nMes missions actuelles portent principalement sur :\n\nLe nettoyage et la qualification d’études RWD.\nLa qualification et le requêtage d’Entrepôts de Données de Santé (bases SQL)\nLe développement d’applications Shiny ou de rapports avec Markdown/Quarto (Suivi de projets, comparaison de bases)\nData Engineering (Automatisation de process, exécution planifiée, requêtage API)\nEnseignement :\n\nCours d’introduction à R et à la gestion de données, auprès d’étudiants de Licence 2 et Master 2 de biologie\nFormations à R au sein de mon service\n\n\n\n\nStack technique\n\nProgrammation :\n\nMaîtrise : R, SQL\nNotions : HTML, CSS, Python, Shell\n\nBases de données :\n\nMS SQL, MySQL, Oracle\n\nVisualisation :\n\nR, Qlik Sense, Power BI\n\nCI/CD :\n\nGit (GitHub, GitLab), Docker\n\nETL :\n\nTalend\n\ne-CRF/EDC :\n\nREDCap, EasyMedStats\n\n\n\n\nRoadmap\nLes compétences que je souhaite développer dans les mois à venir, au 15 juin 2025 :\n\nFinaliser la maîtrise de Duckdb et Arrow pour le Big Data (Juillet 2025) ✅\nPublier une première version de ce site (Rentrée 2025) ✅\nPublier mes supports de cours dans un site Quarto (Rentrée 2025) ✅\nDévelopper mes compétences CI/CD (Automne 2025)\n\nÊtre à l’aise avec le déploiement d’applis Shiny et de documents Quarto sur différents outils de publication (GitHub Pages, Posit Connect, Shinyapps.io) ✅\nDévelopper des applis Shiny Production-grade avec {rhino} et/ou {golem}, en intégrant des tests unitaires, d’intégration et End-to-End\nApprendre la dockerisation et déployer au moins une appli Shiny dans un docker ✅\n\nDécouvrir un client Cloud (GCP/AWS/Azure) (Fin 2025)\nMe former à Databricks (Fin 2025)\nM’initier au Machine Learning (mi-2026)\n\nRemise à niveau en statistiques\nMe former à l’utilisation du package {tidymodels}"
  },
  {
    "objectID": "pages/articles/connections.html",
    "href": "pages/articles/connections.html",
    "title": "R : un outil à tout faire",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/articles/connections.html#google-cloud-platform",
    "href": "pages/articles/connections.html#google-cloud-platform",
    "title": "R : un outil à tout faire",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de googleAuthR\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/articles/connections.html#aws",
    "href": "pages/articles/connections.html#aws",
    "title": "R : un outil à tout faire",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/articles/connections.html#xml",
    "href": "pages/articles/connections.html#xml",
    "title": "R : un outil à tout faire",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/articles/connections.html#json",
    "href": "pages/articles/connections.html#json",
    "title": "R : un outil à tout faire",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/articles/ragnar.html",
    "href": "pages/articles/ragnar.html",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "",
    "text": "Etant plutôt du genre à être dans les derniers à suivre une tendance, mon utilisation des LLM était jusqu’à récemment limitée à poser des questions à chat-GPT ou GitHub Copilot. Il y a environ deux semaines, en discutant avec un ami dont le métier est justement d’accompagner les entreprises dans leur passage à l’IA, celui-ci m’a expliqué les différents mots-clés du domaine : “MCP”, “Agent”, “Contexte” et surtout : la “RAG” (Retrieval-Augmented Generation), ou “Génération Augmentée par Récupération”.\nLa RAG, c’est faire lire des documents à un LLM pour qu’il puisse les utiliser dans ses réponse. Cela revient à ajouter de nouvelles données (que l’on estime fiables) à sa base d’entraînement et permet de le spécialiser dans un domaine.\nCa tombe bien ! Depuis que j’ai commencé à coder, j’utilise Zotero pour indexer des tonnes de guides et d’articles sur R. L’idée m’est immédiatement venue : créer un assistant de code spécialisé en R et en données de santé."
  },
  {
    "objectID": "pages/articles/ragnar.html#récupérer-les-documents",
    "href": "pages/articles/ragnar.html#récupérer-les-documents",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Récupérer les documents",
    "text": "Récupérer les documents\nTout d’abord, commençons par extraire notre bibliothèque Zotero. On aura besoin des PDFs déjà récupérés et des liens vers les documents enregistrés. \nPour les PDFs, dans Zotero allez dans Fichier &gt; Exporter la bibliothèque &gt; Format : “Zotero RDF” et cochez “Exporter les fichiers”. Vous obtiendrez ainsi un dossier “Ma bibliothèque”, qui contient un sous-dossier “files”, qui contient les documents, et un fichier “Ma bibliothèque.rdf” que nous n’utiliserons pas.\nPour obtenir les URLs, exportez simplement votre bibliothèque au format.csv.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(glue)\nlibrary(ragnar)\nlibrary(rollama)\n\n# Récupérer tous les chemins des fichiers PDF dans le dossier \"files\"\npdf_paths &lt;- list.files(\n  path = \"D:/Ma bibliothèque/files/\",\n   pattern = \"\\\\.pdf\", \n   full.names = TRUE, \n   recursive = TRUE)\n\n# Récupérer les liens dans le fichier .csv\nzotero_csv &lt;- read_csv2(\"D:/ma_biblio_csv.csv\") %&gt;%\n  filter(!is.na(Url) | !is.na(`Link Attachments`) )\n\nzotero_urls &lt;- zotero_csv %&gt;% \n  select(Url, `Link Attachments`) %&gt;%\n  unlist() %&gt;%\n  na.omit() %&gt;%\n  unique()\n\n# Ragnar permet aussi de récupérer les liens présents sur une page.\n# On peut ainsir récupérer toutes les pages d'une documentation \n# à partir du lien principal\nzotero_external_links &lt;- c()\nfor(link in zotero_urls){\n  tryCatch({\n    doc &lt;- ragnar_find_links(link, depth = 2)\n    zotero_external_links &lt;- append(zotero_external_links, doc)\n  })\n}\n  \n# On combine le tout pour obtenir un seul vecteur\nfull_links &lt;- c(pdf_paths, zotero_urls, zotero_external_links) %&gt;% \n  unique()\n\n\n\n\n\n\n\nCaution\n\n\n\nMa bibliothèque compte aujourd’hui près d’un millier de documents, et en considérant une moyenne d’une minute par document, il m’a fallu plus de 30 heures pour tout ingérer. Pour faire cette expérience de votre côté, vous pouvez tester avec seulement la documentation du package {rhino} en remplaçant full_links par ce lien : “https://appsilon.github.io/rhino/articles/tutorial/create-your-first-rhino-app.html”"
  },
  {
    "objectID": "pages/articles/ragnar.html#créer-le-store",
    "href": "pages/articles/ragnar.html#créer-le-store",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Créer le store",
    "text": "Créer le store\nLe store est une base DuckDB qui contiendra nos documents, découpés en chunks, pour permettre à l’assistant d’y accéder.\n\n# Si on ne met que le nom, enregistré sous C:/user/votre_nom/ (sur Windows)\nstore_location &lt;- \"zotero_ragnar.duckdb\"\n\n# Créer le store\nstore &lt;- ragnar_store_create(\n  store_location,\n  embed = \\(x) ragnar::embed_ollama(x, model = \"llama3.2:3b-instruct-q4_K_M\"),\n  overwrite = TRUE\n)\n\n# S'y connecter\nstore &lt;- ragnar_store_connect(\"zotero_ragnar.duckdb\", read_only = FALSE)"
  },
  {
    "objectID": "pages/articles/ragnar.html#ingérer-les-documents-dans-le-store",
    "href": "pages/articles/ragnar.html#ingérer-les-documents-dans-le-store",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Ingérer les documents dans le store",
    "text": "Ingérer les documents dans le store\nMaintenant que le store est créé, on va enregistrer nos documents via une boucle. read_as_markdown permet de transformer le document (URL, PDF ou autre) en markdown, puis markdown_chunk permet de le découper en chunk pour que le LLM puisse l’exploiter.\n\n\n\n\n\n\nCaution\n\n\n\nLorsqu’une URL est fournie, {ragnar} va scraper la page. Certains sites n’autorisent pas le webscraping (et c’est leur droit) et vous renverront une erreur 403. Dans ce cas, il n’y a pas grand chose à faire. On ajoutera un tryCatch() à notre boucle pour ne pas la casser si une erreur est renvoyée.\n\n\n\nfor (path in full_links) {\n  tryCatch({\n    chunks &lt;- path |&gt;\n      read_as_markdown() |&gt;\n      markdown_chunk()\n    \n    ragnar_store_insert(store, chunks)\n    # pour visualiser la progression\n    print(which(path == full_links), \"/\", length(full_links))\n\n  }, error = function(e) {\n    cat(\"Error processing\", path, \":\", e$message, \"\\n\")\n    # Optionally log the error or take other action\n  })\n}\n\n# Indispensable pour rendre notre store exploitable\nragnar_store_build_index(store)\n\n# On peut ensuite vérifier l'intégration des documents avec\nragnar_store_inspect(store)"
  },
  {
    "objectID": "pages/articles/ragnar.html#préparer-lassistant",
    "href": "pages/articles/ragnar.html#préparer-lassistant",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Préparer l’assistant",
    "text": "Préparer l’assistant\nOn va tester notre assistant en lui demander de nous aider à utiliser le framework {rhino}, développé par Appsilon pour aider à créer des applications R/Shiny robustes.\n\n# Notre Query\ntext &lt;- \"How to use the {Rhino} R package to create a Shiny app ? Be concise\"\n\n\n# On peut visualiser les chunks les plus pertinents pour notre question avec\nrelevant_chunks &lt;- ragnar_retrieve(store, text)\n\n\n# Définir un prompt de préparation\n# il sera possible d'enregistrer ce prompt dans un .Rprofile pour ne pas avoir à le répéter\nsystem_prompt &lt;- stringr::str_squish(\n  \"\n  You are an expert R programmer and mentor. You are concise.\n\n  Before responding, retrieve relevant material from the knowledge store. Quote or\n  paraphrase passages, clearly marking your own words versus the source. Provide a\n  working link for every source cited, as well as any additional relevant links.\n  Do not answer unless you have retrieved and cited a source.\n  \"\n)"
  },
  {
    "objectID": "pages/articles/ragnar.html#discuter-avec-lassistant",
    "href": "pages/articles/ragnar.html#discuter-avec-lassistant",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Discuter avec l’assistant",
    "text": "Discuter avec l’assistant\nOn va tout d’abord tester notre assistant, pour voir s’il connait le package {rhino} :\n\nchat &lt;- ellmer::chat_ollama(\n  system_prompt,\n  model = \"llama3.2:3b-instruct-q4_K_M\"\n)\n\nchat$chat(text)\n\n\n# I'm unable to retrieve accurate information regarding the \"{Rhino}\" R package without more context. However, I can provide general guidance on creating a Shiny app using the Shiny package in R.\n# \n# To start building a Shiny app:\n# \n# 1.  Install and load the `shiny` package:\n# \n# ``` r\n# install.packages(\"shiny\")\n# library(shiny)\n# ....\n\nPour le moment, il est incapable de répondre. \nOn va maintenant lui donner accès au store :\n\nragnar_register_tool_retrieve(chat, store)\nchat$chat(text)\n\n\n\n# ◯ \\[tool call\\] rag_retrieve_from_store_003(text = \" installing and loading shiny package\") ● #\\&gt; \\[{\"origin\":\"https://appsilon.github.io/rhino/articles/tutorial/create-your-first-rhino-app.html\",\"doc_id\":1,\"ch… To create a Shiny app using the Rhino package, follow these steps:\n# \n# 1.  Install Rhino: `package::install(\"rhino\")`\n# 2.  Create an initial Rhino application: `rhino::init(\"RhinoApplication\")`\n# \n# Install necessary packages:\n# \n# ``` r\n# # In R console\n# rhino::pkg_install(c(\n#   \"dplyr\",\n#   \"echarts4r\",\n#   \"htmlwidgets\",\n#   \"reactable\",\n#   \"tidyr\"\n# ))\n# ```\n# .....\n\nVictoire ! Notre assistant connaît désormais {rhino} et peut nous accompagner pour le développement d’applications Shiny plus poussées !\nIl ne reste plus qu’à continuer avec tous les documents de notre bibliothèque pour développer les connaissances de notre assistant.\nNotre modèle étant installé en local, l’assistant fonctionne même sans connection internet, de façon illimitée et gratuite. Si le modèle n’est pas assez performant pour vous, vous pouvez parcourir la liste de modèles Ollama pour en trouver un plus adapté à votre usage.\n\n\n\n\n\n\nTip\n\n\n\n\nPour ajouter de nouveaux documents, on peut créer une nouvelle boucle avec ragnar_store_insert et ragnar_store_build_index(). On passera simplement l’étape ragnar_store_create() pour passer directement à ragnar_store_connect()\nPour que l’assistant soit prêt dès le lancement de notre IDE, on peut enregistrer les étapes suivantes dans un .Rprofile\n\nragnar_store_connect()\nLe system_prompt\nLa création de chat avec ellmer::chat_ollama()"
  },
  {
    "objectID": "pages/tidytuesday/20250914/frogs.html",
    "href": "pages/tidytuesday/20250914/frogs.html",
    "title": "Frogs",
    "section": "",
    "text": "Source : australian.museum\nCette semaine, le tidytuesday porte sur des données d’observations de grenouilles en Australie, dont l’article est diponible ici \nPour cette première participation, je vais simplement créer une heatmap pour visualiser la densité des observations sur la carte de l’Australie. Pour cela, on aura besoin du package {leaflet} et {leaflet.extras}\nDans un premier temps, on va récupérer les données de la semaine.\n\nlibrary(tidytuesdayR)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(leaflet.extras)\n\ntuesdata &lt;- tt_load(\"2025-09-02\")\n\nfrog_id &lt;- tuesdata$frogID_data\n\nL’étape de transformation de données sera assez simple :\n\nNettoyer les noms de colonnes\nCompter le nombre d’observation pour chaque combinaison de coordonnées\n\n\ndf &lt;- frog_id %&gt;% \n  select(lat = decimalLatitude, \n         lon = decimalLongitude,\n         name = scientificName) %&gt;%\n  group_by(lat, lon) %&gt;%\n  count()\n\nPour le plaisir, je rajouterai les provinces du pays sur la carte. \nEnsuite, il suffit de créer la carte avec `leaflet()`.\n\n# Créer le nom des provinces\naus_provinces &lt;- data.frame(\n  name = c(\"New South Wales\", \"Victoria\", \"Queensland\", \"Western Australia\",\n           \"South Australia\", \"Tasmania\", \"Northern Territory\"),\n  latitude = c(-32, -36.5, -25, -26, -30, -42, -20),\n  longitude = c(151, 145, 148, 117, 137, 147, 131)\n)\n\n\nleaflet(df) %&gt;%\n  addTiles() %&gt;%\n  addHeatmap(\n    lng = ~ lon,\n    lat = ~ lat,\n    intensity = ~ n,\n    blur = 1,\n    max = 10, \n    radius = 15\n  )  %&gt;%\n  addLabelOnlyMarkers(\n    lng = ~ aus_provinces$longitude,\n    lat = ~aus_provinces$latitude,\n    label = ~ aus_provinces$name,\n    labelOptions = labelOptions(noHide = TRUE, direction = 'auto', textOnly = TRUE)\n  )\n\n\n\n\n\nCette carte permet de voir facilement que la côte Ouest a une densité d’observation bien plus importante que le reste du pays, principalement autour de Syndey et Melbourne, avec également un grand nombre d’observations autour de Perth à l’Ouest."
  },
  {
    "objectID": "pages/articles.html",
    "href": "pages/articles.html",
    "title": "Articles",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\nCautionCette section est encore en travaux !\n\n\n\nPlus d’articles seront bientôt publiés ici\n\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n\n\n\n\n\n\n\n\n\n\nCréer un assistant de code personnel avec {ragnar} et Zotero\n\n\n\nR\n\nIA\n\nLLM\n\n\n\nComment entraîner un modèle LLM open-source sur des documents pour se faire un assistant de code spécialisé dans son domaine d’expertise\n\n\n\nFélix Marchais\n\n\nOct 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nR : un outil à tout faire\n\n\n\nR\n\nBases de données\n\n\n\nSe connecter à tout type de données avec R, en local ou sur le cloud\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\nNo matching items"
  }
]