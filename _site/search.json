[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue",
    "section": "",
    "text": "Développeur R et Data Manager de données cliniques \nDiplômé d’un Master 2 de Biologie - Physiopathologie & Recherche Clinique \nJe me suis spécialisé dans la programmation en R pour des missions de traitement de données de santé, visualisation et automatisation de process. \nDans ce portfolio, vous pourrez retrouver plus de détails sur mon profil, découvrir les différents usages de R et mes différents projets"
  },
  {
    "objectID": "pages/liste_projets.html",
    "href": "pages/liste_projets.html",
    "title": "Projets",
    "section": "",
    "text": "Ci-dessous vous pourrez retrouver des outils développés pour des projets professionnels ou personnels. \n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_usages/recueil_nettoyage.html",
    "href": "pages/r_usages/recueil_nettoyage.html",
    "title": "Recueil et transformation de données",
    "section": "",
    "text": "Recueil de données\nR est un langage qui permet d’intéragir avec à peu près n’importe quel format de données \nDes fichiers tabulaires (CSV, Excel, Parquet…), en local ou sur un serveur\nDes bases SQL/NoSQL : MS SQL Server, MySQL, MongoDB, Oracle, DuckDB…\nDes données hébergées sur un cloud (GCP, AWS, Azure…)\nDes données récupérées via du webscraping ou une requête API\nDes données au format JSON ou XML\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, générer des documents Word ou Powerpoint, et bien plus encore.\n\n\nNettoyage\nL’une des grandes forces de R est le Tidyverse: un ensemble de packages qui permettent de manipuler les données avec facilité."
  },
  {
    "objectID": "pages/profil.html",
    "href": "pages/profil.html",
    "title": "Profil",
    "section": "",
    "text": "A propos de moi\nIssu d’un parcours en Biologie et Recherche Clinique, je me suis rapidement dirigé vers le traitement de données de santé à la fin de l’année de Master 1, en me formant en autodidacte au langage R.\nMon parcours professionnel m’a amené à travailler dans le milieu du Dispositif Médical (DM) en orthopédie, puis dans les études de vie réelle (RWD) en cancérologie.\nMes missions actuelles portent principalement sur :\n\nLe nettoyage et la qualification d’études RWD.\nLa qualification et le requêtage d’Entrepôts de Données de Santé (bases SQL)\nLe développement d’applications Shiny ou de rapports avec Markdown/Quarto (Suivi de projets, comparaison de bases)\nData Engineering (Automatisation de process, exécution planifiée, requêtage API)\nEnseignement :\n\nCours d’introduction à R et à la gestion de données, auprès d’étudiants de Licence 2 et Master 2 de biologie\nFormations à R au sein de mon service\n\n\n\n\nStack technique\n\nProgrammation :\n\nMaîtrise : R, SQL\nNotions : HTML, CSS, Python, Shell\n\nBases de données :\n\nMS SQL, MySQL, Oracle\n\nVisualisation :\n\nR, Qlik Sense, Power BI\n\nCI/CD :\n\nGit (GitHub, GitLab), Docker (en cours)\n\nETL :\n\nTalend\n\ne-CRF/EDC :\n\nREDCap, EasyMedStats\n\nCatalogues :\n\nOpen Metadata\n\n\n\n\nRoadmap\nLes compétences que je souhaite développer dans les mois à venir, au 15 juin 2025 :\n\nFinaliser la maîtrise de Duckdb et Arrow pour le Big Data (Juillet 2025) ✅\nPublier une première version de ce site (Rentrée 2025) ✅\nPublier mes supports de cours dans un site Quarto (Rentrée 2025)\nDévelopper mes compétences CI/CD (Automne 2025)\n\nÊtre à l’aise avec le déploiement d’applis Shiny et de documents Quarto sur différents outils de publication (GitHub Pages, Posit Connect, Shinyapps.io) ✅\nDévelopper des applis Shiny Production-grade avec {rhino} et/ou {golem}, en intégrant des tests unitaires, d’intégration et End-to-End\nApprendre la dockerisation et déployer au moins une appli Shiny dans un docker\n\nDécouvrir un client Cloud (GCP/AWS/Azure) (Fin 2025)\nMe former à Databricks (Fin 2025)\nM’initier au Machine Learning (mi-2026)\n\nRemise à niveau en statistiques\nMe former à l’utilisation du package {tidymodels}"
  },
  {
    "objectID": "pages/profil.html#analyse-visualisation",
    "href": "pages/profil.html#analyse-visualisation",
    "title": "Profil",
    "section": "Analyse & Visualisation",
    "text": "Analyse & Visualisation\nggplot2 et dérivés,\ngwalkr\nstats"
  },
  {
    "objectID": "pages/profil.html#reporting",
    "href": "pages/profil.html#reporting",
    "title": "Profil",
    "section": "Reporting",
    "text": "Reporting\n\nRmarkdown\n\n\nQuarto\n\n\nR Shiny"
  },
  {
    "objectID": "pages/profil.html#data-engineering",
    "href": "pages/profil.html#data-engineering",
    "title": "Profil",
    "section": "Data Engineering",
    "text": "Data Engineering\n\nOrchestrateur\n{maestro} est un package R permettant d’orchestrer l’exécution programmée de différents scripts R, permettant ainsi de créer de gérer des pipelines de données.\n\n\nBases de données (SQL)\n\n\nAPI\nhittr2\n\n\nCI/CD\nGitHub, testthat, usethis\nDocker (dockerfiler, rocker, shiny2docker, dockitect …\n\n\nCloud\nun exemple d’interaction avec différents services d’un cloud (stockage, faire tourner R sur un serveur…)"
  },
  {
    "objectID": "pages/tidytuesday.html",
    "href": "pages/tidytuesday.html",
    "title": "Tidytuesday",
    "section": "",
    "text": "Le Tidytuesday, c’est un évènement qui a lieu chaque semaine, où la communauté R se challenge pour créer des visualisations à partir d’un nouveau jeu de données, publié tous les mardis. \n\n\n\n\n\n\n\n\n\n\n\n\nTidytuesday - 2025-09-02\n\n\nObservations des grenouilles en Australie\n\n\n\nFélix Marchais\n\n\nSep 14, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/liste_usages.html",
    "href": "pages/liste_usages.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html",
    "href": "pages/r_usages/usages_connexion.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#les-fichiers-plats-en-local",
    "href": "pages/r_usages/usages_connexion.html#les-fichiers-plats-en-local",
    "title": "Recueil de données",
    "section": "",
    "text": "Commençons avec le plus simple : les fichiers CSV\n\n\n\nlibrary(readr) # package du Tidyverse\nread_csv(\"path/to/file.csv\")\n\nOn fait difficilement plus facile. On notera tout de même que {readr} offre des arguments et fonctions supplémentaires pour gérer différents problèmes que l’on rencontre souvent avec le CSV : les séparateurs et l’encodage. \nLa fonction read_csv lit par défaut des fichiers au “format international” dont le séparateur est une virgule (,) et la décimale un point (.). Cependant, en France (et en Europe), on utilisé généralement la virgule comme séparateur décimal. On a donc inventé le format csv avec séparateur point-virgule (;) et décimale en virgule (,). Pour lire un fichier sous ce format, on peut utiliser la fonction read_csv2() de {readr}. \nPour des formats encore plus exotiques (tsv par exemple), read_delim() permet de préciser le délimiteur. \nOn notera aussi que les fonctions read_*() fournissent des arguments permettant d’expliciter les valeurs nulles, de retirer les espaces en début/fin de chaîne (ce qui arrive très souvent sur des données saisies à la main dans Excel), de différencier des noms de colonnes en doublons, ou encore de sauter les premières lignes d’un fichier.\n\nlibrary(readr)\nread_csv2(\"path/to/file_fr.csv\", # lire un fichier au format FR, delim = ;\n          na = c(\"\",\"NULL\",\"NA\"), # les cases contenant \"\",\"NULL\" et \"NA\" seront vides\n          trim_ws = TRUE, # trim_whitespace : retirer les espaces en fin de chaîne\n          skip = 1, # sauter la première ligne\n          name_repair = \"unique\" # différencier les noms en doublons\n)"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#fichiers-plats-à-distance",
    "href": "pages/r_usages/usages_connexion.html#fichiers-plats-à-distance",
    "title": "Recueil de données",
    "section": "",
    "text": "Les fonctions read.*() (en base R) et read_*() ({readr}) permettent toutes de télécharger des données via une URL.\n\ncovid_data &lt;- readr::read_csv2(\"https://www.data.gouv.fr/api/1/datasets/r/fe3e7099-a975-4181-9fb5-2dd1b8f1b552\")\nhead(covid_data)\n\n# A tibble: 6 × 9\n  fra   strate2 jour       PourAvec tx_indic_7J_DC tx_indic_7J_hosp\n  &lt;chr&gt;   &lt;dbl&gt; &lt;date&gt;        &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;           \n1 FR          0 2020-03-07        0 0              0               \n2 FR          0 2020-03-07        1 &lt;NA&gt;           0               \n3 FR          0 2020-03-07        2 &lt;NA&gt;           0               \n4 FR          0 2020-03-08        0 0              0               \n5 FR          0 2020-03-08        1 &lt;NA&gt;           0               \n6 FR          0 2020-03-08        2 &lt;NA&gt;           0               \n# ℹ 3 more variables: tx_indic_7J_SC &lt;chr&gt;, tx_prev_hosp &lt;dbl&gt;,\n#   tx_prev_SC &lt;chr&gt;\n\n\n\n\nLes fichiers dits “Excel” ont l’extension .xls ou .xlsx, et peuvent contenir différents feuillets, de la mise en forme, des cellules fusionnées, des formules, des commentaires et des graphes. \nPour lire ces données, il existe plusieurs librairies : {readxl}, {openxslx} ou {openxslx2}\n\nlibrary(readxl)\nread_excel(\"path/to/file.xslx\",\n           sheet = 1, # feuillet, par numéro ou par nom\n           range = \"B3:D87\", # les cellules à garder\n           na = c(\"\",\"NULL\",\"NA\"), # les cellules à considérer vides\n           .name_repair = \"unique\" # différencier les noms en doublons\n)\n\n\n\n\nLe format .parquet, encore malheureusement peu connu, est un format compressé et orienté en colonnes, orienté vers la performance. Un même jeu de données au format parquet est entre 5 et 10 fois moins volumineux qu’en csv et est optimisé pour être lu rapidement par R ou Python. On citera aussi sa compatibilité avec DuckDB pour former un duo parfait pour travailler le Big Data avec R. L’un des rares défauts qu’on peut lui trouver est de ne pas être compatible avec Excel, ce qui limite sa diffusion. \nSi vous ne l’avez pas encore lu, je vous renvoie vers cet excellent article : Parquet devrait remplacer le format CSV\nIl existe deux méthodes principales pour lire un fichier parquet en R : {arrow}, la librairie de Apache Arrow et {duckDB}, la librairie de DuckDB.\nLes deux méthodes permettent de créer une connexion vers le jeu de données, au lieu de les importer dans la mémoire de R, permettant de travailler avec des données pus volumineuses que la RAM. Les deux méthodes permettent d’utiliser {dplyr} pour le requêtage, mais {duckdb} permet aussi de requêter n’importe quel fichier plat en SQL. \nOn notera également la capacité à lire plusieurs fichiers regroupés dans un dossier (ayant le même schéma), voire même des fichiers partitionnés (au style Hive), permettant de ne scanner que les données nécessaires, pour optimiser encore plus la performance de requêtage.\n\n# Arrow : \nlibrary(arrow)\narrow_df &lt;- read_parquet(\"path/to/file.parquet\")\n\n# Il est possible de lire directement un ensemble de fichiers .parquet ayant le même schéma \n# et regroupés dans un dossier (données par batch, avec un fichier par mois par exemple)\narrow_dataset &lt;- open_dataset(\"path/to/folder\")\n\n\n\n# DuckDB :\nlibrary(duckdb)\nlibrary(DBI) # DataBase Interface\n\nconn_ddb &lt;- DBI::dbConnect(duck(), dbdir = \":memory:\") # Créer une base duckdb virtuelle\nduck_df &lt;- conn_ddb |&gt; tbl(\"path/dataset/**/*.parquet\")\n# Le ** signifie \"tout\", et permet de lire tous les fichiers parquet du dossier\n# Dans un fichier partitionné par exemple"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#connexions-aux-bases-sql",
    "href": "pages/r_usages/usages_connexion.html#connexions-aux-bases-sql",
    "title": "Recueil de données",
    "section": "",
    "text": "Si vous utilisez Rstudio, le moyen le plus simple de se connecter à une source de données est d’utiliser l’onglet Connections, généralement situé en haut à droite, avec votre Environnement. En cliquant sur New connection, une fenêtre apparaît et va automatiquement vous proposer les sources à disposition. \n\n\n\nExemple des connections existantes sur mon poste\n\n\nSi vous avez déjà configuré un DSN contenant vos identifiants, les informations de connection devraient déjà être remplies, vous n’avez plus qu’à cliquer sur “OK”, et le code s’exécutera dans la console. Vous pourrez alors visualiser vos bases dans l’onglet Connections\n\nSinon, vous aurez besoin d’entrer les paramètres suivants :\n\nuser = “…” pour le nom d’utilisateur\npassword = “…” pour le mot de passe\nhost et port si besoin\ndbname pour le nom de la base de données\n\nSi vous utilisez uniquement la console, vous pouvez rentrer directement les paramètres dans dbConnect(), en arguments de la fonction.\nUne fois connecté, on peut requêter ses données avec {dplyr} ou en SQL, en utilisant dbGetQuery()\n\nlibrary(DBI)\nlibrary(odbc)\nconn &lt;- DBI::dbConnect(odbc::odbc()) \"server-name\", database = \"MA_BASE\")\n\n# SQL\nma_table &lt;- DBI::dbGetQuery(conn, \n                            \"SELECT * FROM MA_TABLE\n                            WHERE ...\")\n\n\n# DPLYR\nlibrary(dplyr)\nma_table_2 &lt;- dplyr::tbl(conn, \"MA_TABLE\") %&gt;% # ici, on créé une connexion à la table\n  dplyr::filter(...) %&gt;% # on créé la requête\n  dplyr::collect() # et on collecte le résultat dans R avec collect()\n\nPour interagir avec une base SQL pour autre chose qu’une requête (UPDATE, DROP, …), on peut utiliser la librairie {dbplyr}, un back-end de {dplyr} pour les bases de données, ou utiliser DBI::dbExecute()"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#cloud",
    "href": "pages/r_usages/usages_connexion.html#cloud",
    "title": "Recueil de données",
    "section": "",
    "text": "R dispose de nombreuses librairies pour récupérer des données hébergées sur un serveur cloud. Je n’entrerai pas dans les détails de cette partie, car je n’ai pas encore eu beaucoup l’occasion de pratiquer par moi-même, mais je penserai à la mettre à jour dès que possible. \n\n\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build\n\n\n\n\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R :"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#google-cloud-platform",
    "href": "pages/r_usages/usages_connexion.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#aws",
    "href": "pages/r_usages/usages_connexion.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#info",
    "href": "pages/r_usages/usages_connexion.html#info",
    "title": "Recueil de données",
    "section": "Info",
    "text": "Info\nRécemment, {duckplyr}, une librairie intégrant {dplyr} avec le moteur de {duckdb} a rejoint le Tidyverse, signe que Duckdb est perçu comme un outil d’avenir. Lire l’article"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html",
    "href": "pages/r_decouvrir/decouvrir_connections.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#google-cloud-platform",
    "href": "pages/r_decouvrir/decouvrir_connections.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#aws",
    "href": "pages/r_decouvrir/decouvrir_connections.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/liste_decouvrir.html",
    "href": "pages/liste_decouvrir.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#xml",
    "href": "pages/r_decouvrir/decouvrir_connections.html#xml",
    "title": "Recueil de données",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#json",
    "href": "pages/r_decouvrir/decouvrir_connections.html#json",
    "title": "Recueil de données",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/decouvrir_r.html",
    "href": "pages/decouvrir_r.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/projets.html",
    "href": "pages/projets.html",
    "title": "Projets",
    "section": "",
    "text": "Ci-dessous vous pourrez retrouver des outils développés pour des projets professionnels ou personnels. \n\n\n\n\n\n\nCette section est encore en travaux !\n\n\n\nDes projets seront bientôt publiés ici\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGestionnaire_projets\n\n\nUn tableau de bord pour les chefs de projets\n\n\n\nFélix Marchais\n\n\nSep 15, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html",
    "href": "pages/decouvrir_r/decouvrir_connections.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#google-cloud-platform",
    "href": "pages/decouvrir_r/decouvrir_connections.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#aws",
    "href": "pages/decouvrir_r/decouvrir_connections.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#xml",
    "href": "pages/decouvrir_r/decouvrir_connections.html#xml",
    "title": "Recueil de données",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#json",
    "href": "pages/decouvrir_r/decouvrir_connections.html#json",
    "title": "Recueil de données",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/tidytuesday/20250914/tidytuesday_20250914.html",
    "href": "pages/tidytuesday/20250914/tidytuesday_20250914.html",
    "title": "Tidytuesday - 2025-09-02",
    "section": "",
    "text": "Source : australian.museum\nCette semaine, le tidytuesday porte sur des données d’observations de grenouilles en Australie, dont l’article est diponible ici \nPour cette première participation, je vais simplement créer une heatmap pour visualiser la densité des observations sur la carte de l’Australie. Pour cela, on aura besoin du package {leaflet} et {leaflet.extras}\nDans un premier temps, on va récupérer les données de la semaine.\n\nlibrary(tidytuesdayR)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(leaflet.extras)\n\ntuesdata &lt;- tt_load(\"2025-09-02\")\n\nfrog_id &lt;- tuesdata$frogID_data\n\nL’étape de transformation de données sera assez simple :\n\nNettoyer les noms de colonnes\nCompter le nombre d’observation pour chaque combinaison de coordonnées\n\n\ndf &lt;- frog_id %&gt;% \n  select(lat = decimalLatitude, \n         lon = decimalLongitude,\n         name = scientificName) %&gt;%\n  group_by(lat, lon) %&gt;%\n  count()\n\nPour le plaisir, je rajouterai les provinces du pays sur la carte. \nEnsuite, il suffit de créer la carte avec `leaflet()`.\n\n# Créer le nom des provinces\naus_provinces &lt;- data.frame(\n  name = c(\"New South Wales\", \"Victoria\", \"Queensland\", \"Western Australia\",\n           \"South Australia\", \"Tasmania\", \"Northern Territory\"),\n  latitude = c(-32, -36.5, -25, -26, -30, -42, -20),\n  longitude = c(151, 145, 148, 117, 137, 147, 131)\n)\n\n\nleaflet(df) %&gt;%\n  addTiles() %&gt;%\n  addHeatmap(\n    lng = ~ lon,\n    lat = ~ lat,\n    intensity = ~ n,\n    blur = 1,\n    max = 10, \n    radius = 15\n  )  %&gt;%\n  addLabelOnlyMarkers(\n    lng = ~ aus_provinces$longitude,\n    lat = ~aus_provinces$latitude,\n    label = ~ aus_provinces$name,\n    labelOptions = labelOptions(noHide = TRUE, direction = 'auto', textOnly = TRUE)\n  )\n\n\n\n\n\nCette carte permet de voir facilement que la côte Ouest a une densité d’observation bien plus importante que le reste du pays, principalement autour de Syndey et Melbourne, avec également un grand nombre d’observations autour de Perth à l’Ouest."
  },
  {
    "objectID": "pages/projets/Gestionnaire_projets.html",
    "href": "pages/projets/Gestionnaire_projets.html",
    "title": "Gestionnaire_projets",
    "section": "",
    "text": "Cette application Shiny a été créée comme un tableau de bord permettant à un chef de projet de suivre l’avancée de différentes études. A partir d’un jeu de données fictif chargé dans l’application, il est possible de suivre le nombre et le détail des projets, ainsi que le calendrier de chaque projet et la charge de travail à venir.\nL’application est disponible ici"
  }
]