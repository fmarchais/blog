[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue",
    "section": "",
    "text": "Ce blog est encore en travaux !\n\n\n\nVous verrez bientôt ma tête ici\n\n\nDéveloppeur R et Data Manager de données cliniques \nDiplômé d’un Master 2 de Biologie - Physiopathologie & Recherche Clinique \nJe me suis spécialisé dans la programmation en R pour des missions de traitement de données de santé, visualisation et automatisation de process. \nDans ce blog, vous pourrez retrouver plus de détails sur mon profil, découvrir les différents usages de R et mes différents projets"
  },
  {
    "objectID": "pages/liste_projets.html",
    "href": "pages/liste_projets.html",
    "title": "Projets",
    "section": "",
    "text": "Ci-dessous vous pourrez retrouver des outils développés pour des projets professionnels ou personnels. \n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_usages/recueil_nettoyage.html",
    "href": "pages/r_usages/recueil_nettoyage.html",
    "title": "Recueil et transformation de données",
    "section": "",
    "text": "Recueil de données\nR est un langage qui permet d’intéragir avec à peu près n’importe quel format de données \nDes fichiers tabulaires (CSV, Excel, Parquet…), en local ou sur un serveur\nDes bases SQL/NoSQL : MS SQL Server, MySQL, MongoDB, Oracle, DuckDB…\nDes données hébergées sur un cloud (GCP, AWS, Azure…)\nDes données récupérées via du webscraping ou une requête API\nDes données au format JSON ou XML\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, générer des documents Word ou Powerpoint, et bien plus encore.\n\n\nNettoyage\nL’une des grandes forces de R est le Tidyverse: un ensemble de packages qui permettent de manipuler les données avec facilité."
  },
  {
    "objectID": "pages/profil.html",
    "href": "pages/profil.html",
    "title": "Profil",
    "section": "",
    "text": "A propos de moi\nIssu d’un parcours en Biologie et Recherche Clinique, je me suis rapidement dirigé vers le traitement de données de santé à la fin de l’année de Master 1, en me formant en autodidacte au langage R.\nMon parcours professionnel m’a amené à travailler dans le milieu du Dispositif Médical (DM) en orthopédie, puis dans les études de vie réelle (RWD) en cancérologie.\nMes missions actuelles portent principalement sur :\n\nLe nettoyage et la qualification d’études RWD.\nLa qualification et le requêtage d’Entrepôts de Données de Santé (bases SQL)\nLe développement d’applications Shiny ou de rapports avec Markdown/Quarto (Suivi de projets, comparaison de bases)\nData Engineering (Automatisation de process, exécution planifiée, requêtage API)\nEnseignement :\n\nCours d’introduction à R et à la gestion de données, auprès d’étudiants de Licence 2 et Master 2 de biologie\nFormations à R au sein de mon service\n\n\n\n\nStack technique\n\nProgrammation :\n\nMaîtrise : R, SQL\nNotions : HTML, CSS, Python, Shell\n\nBases de données :\n\nMS SQL, MySQL, Oracle\n\nVisualisation :\n\nR, Qlik Sense, Power BI\n\nCI/CD :\n\nGit (GitHub, GitLab), Docker\n\nETL :\n\nTalend\n\ne-CRF/EDC :\n\nREDCap, EasyMedStats\n\n\n\n\nRoadmap\nLes compétences que je souhaite développer dans les mois à venir, au 15 juin 2025 :\n\nFinaliser la maîtrise de Duckdb et Arrow pour le Big Data (Juillet 2025) ✅\nPublier une première version de ce site (Rentrée 2025) ✅\nPublier mes supports de cours dans un site Quarto (Rentrée 2025) ✅\nDévelopper mes compétences CI/CD (Automne 2025)\n\nÊtre à l’aise avec le déploiement d’applis Shiny et de documents Quarto sur différents outils de publication (GitHub Pages, Posit Connect, Shinyapps.io) ✅\nDévelopper des applis Shiny Production-grade avec {rhino} et/ou {golem}, en intégrant des tests unitaires, d’intégration et End-to-End\nApprendre la dockerisation et déployer au moins une appli Shiny dans un docker ✅\n\nDécouvrir un client Cloud (GCP/AWS/Azure) (Fin 2025)\nMe former à Databricks (Fin 2025)\nM’initier au Machine Learning (mi-2026)\n\nRemise à niveau en statistiques\nMe former à l’utilisation du package {tidymodels}"
  },
  {
    "objectID": "pages/profil.html#analyse-visualisation",
    "href": "pages/profil.html#analyse-visualisation",
    "title": "Profil",
    "section": "Analyse & Visualisation",
    "text": "Analyse & Visualisation\nggplot2 et dérivés,\ngwalkr\nstats"
  },
  {
    "objectID": "pages/profil.html#reporting",
    "href": "pages/profil.html#reporting",
    "title": "Profil",
    "section": "Reporting",
    "text": "Reporting\n\nRmarkdown\n\n\nQuarto\n\n\nR Shiny"
  },
  {
    "objectID": "pages/profil.html#data-engineering",
    "href": "pages/profil.html#data-engineering",
    "title": "Profil",
    "section": "Data Engineering",
    "text": "Data Engineering\n\nOrchestrateur\n{maestro} est un package R permettant d’orchestrer l’exécution programmée de différents scripts R, permettant ainsi de créer de gérer des pipelines de données.\n\n\nBases de données (SQL)\n\n\nAPI\nhittr2\n\n\nCI/CD\nGitHub, testthat, usethis\nDocker (dockerfiler, rocker, shiny2docker, dockitect …\n\n\nCloud\nun exemple d’interaction avec différents services d’un cloud (stockage, faire tourner R sur un serveur…)"
  },
  {
    "objectID": "pages/tidytuesday.html",
    "href": "pages/tidytuesday.html",
    "title": "Tidytuesday",
    "section": "",
    "text": "Le Tidytuesday, c’est un évènement qui a lieu chaque semaine, où la communauté R se challenge pour créer des visualisations à partir d’un nouveau jeu de données, publié tous les mardis. \n\n\n\n\n\n\n\n\n\n\n\n\nCranes\n\n\nObservations de grues en Suède\n\n\n\nFélix Marchais\n\n\nOct 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFrogs\n\n\nObservations des grenouilles en Australie - 2025-09-02\n\n\n\nFélix Marchais\n\n\nSep 14, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/liste_usages.html",
    "href": "pages/liste_usages.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html",
    "href": "pages/r_usages/usages_connexion.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#les-fichiers-plats-en-local",
    "href": "pages/r_usages/usages_connexion.html#les-fichiers-plats-en-local",
    "title": "Recueil de données",
    "section": "",
    "text": "Commençons avec le plus simple : les fichiers CSV\n\n\n\nlibrary(readr) # package du Tidyverse\nread_csv(\"path/to/file.csv\")\n\nOn fait difficilement plus facile. On notera tout de même que {readr} offre des arguments et fonctions supplémentaires pour gérer différents problèmes que l’on rencontre souvent avec le CSV : les séparateurs et l’encodage. \nLa fonction read_csv lit par défaut des fichiers au “format international” dont le séparateur est une virgule (,) et la décimale un point (.). Cependant, en France (et en Europe), on utilisé généralement la virgule comme séparateur décimal. On a donc inventé le format csv avec séparateur point-virgule (;) et décimale en virgule (,). Pour lire un fichier sous ce format, on peut utiliser la fonction read_csv2() de {readr}. \nPour des formats encore plus exotiques (tsv par exemple), read_delim() permet de préciser le délimiteur. \nOn notera aussi que les fonctions read_*() fournissent des arguments permettant d’expliciter les valeurs nulles, de retirer les espaces en début/fin de chaîne (ce qui arrive très souvent sur des données saisies à la main dans Excel), de différencier des noms de colonnes en doublons, ou encore de sauter les premières lignes d’un fichier.\n\nlibrary(readr)\nread_csv2(\"path/to/file_fr.csv\", # lire un fichier au format FR, delim = ;\n          na = c(\"\",\"NULL\",\"NA\"), # les cases contenant \"\",\"NULL\" et \"NA\" seront vides\n          trim_ws = TRUE, # trim_whitespace : retirer les espaces en fin de chaîne\n          skip = 1, # sauter la première ligne\n          name_repair = \"unique\" # différencier les noms en doublons\n)"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#fichiers-plats-à-distance",
    "href": "pages/r_usages/usages_connexion.html#fichiers-plats-à-distance",
    "title": "Recueil de données",
    "section": "",
    "text": "Les fonctions read.*() (en base R) et read_*() ({readr}) permettent toutes de télécharger des données via une URL.\n\ncovid_data &lt;- readr::read_csv2(\"https://www.data.gouv.fr/api/1/datasets/r/fe3e7099-a975-4181-9fb5-2dd1b8f1b552\")\nhead(covid_data)\n\n# A tibble: 6 × 9\n  fra   strate2 jour       PourAvec tx_indic_7J_DC tx_indic_7J_hosp\n  &lt;chr&gt;   &lt;dbl&gt; &lt;date&gt;        &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;           \n1 FR          0 2020-03-07        0 0              0               \n2 FR          0 2020-03-07        1 &lt;NA&gt;           0               \n3 FR          0 2020-03-07        2 &lt;NA&gt;           0               \n4 FR          0 2020-03-08        0 0              0               \n5 FR          0 2020-03-08        1 &lt;NA&gt;           0               \n6 FR          0 2020-03-08        2 &lt;NA&gt;           0               \n# ℹ 3 more variables: tx_indic_7J_SC &lt;chr&gt;, tx_prev_hosp &lt;dbl&gt;,\n#   tx_prev_SC &lt;chr&gt;\n\n\n\n\nLes fichiers dits “Excel” ont l’extension .xls ou .xlsx, et peuvent contenir différents feuillets, de la mise en forme, des cellules fusionnées, des formules, des commentaires et des graphes. \nPour lire ces données, il existe plusieurs librairies : {readxl}, {openxslx} ou {openxslx2}\n\nlibrary(readxl)\nread_excel(\"path/to/file.xslx\",\n           sheet = 1, # feuillet, par numéro ou par nom\n           range = \"B3:D87\", # les cellules à garder\n           na = c(\"\",\"NULL\",\"NA\"), # les cellules à considérer vides\n           .name_repair = \"unique\" # différencier les noms en doublons\n)\n\n\n\n\nLe format .parquet, encore malheureusement peu connu, est un format compressé et orienté en colonnes, orienté vers la performance. Un même jeu de données au format parquet est entre 5 et 10 fois moins volumineux qu’en csv et est optimisé pour être lu rapidement par R ou Python. On citera aussi sa compatibilité avec DuckDB pour former un duo parfait pour travailler le Big Data avec R. L’un des rares défauts qu’on peut lui trouver est de ne pas être compatible avec Excel, ce qui limite sa diffusion. \nSi vous ne l’avez pas encore lu, je vous renvoie vers cet excellent article : Parquet devrait remplacer le format CSV\nIl existe deux méthodes principales pour lire un fichier parquet en R : {arrow}, la librairie de Apache Arrow et {duckDB}, la librairie de DuckDB.\nLes deux méthodes permettent de créer une connexion vers le jeu de données, au lieu de les importer dans la mémoire de R, permettant de travailler avec des données pus volumineuses que la RAM. Les deux méthodes permettent d’utiliser {dplyr} pour le requêtage, mais {duckdb} permet aussi de requêter n’importe quel fichier plat en SQL. \nOn notera également la capacité à lire plusieurs fichiers regroupés dans un dossier (ayant le même schéma), voire même des fichiers partitionnés (au style Hive), permettant de ne scanner que les données nécessaires, pour optimiser encore plus la performance de requêtage.\n\n# Arrow : \nlibrary(arrow)\narrow_df &lt;- read_parquet(\"path/to/file.parquet\")\n\n# Il est possible de lire directement un ensemble de fichiers .parquet ayant le même schéma \n# et regroupés dans un dossier (données par batch, avec un fichier par mois par exemple)\narrow_dataset &lt;- open_dataset(\"path/to/folder\")\n\n\n\n# DuckDB :\nlibrary(duckdb)\nlibrary(DBI) # DataBase Interface\n\nconn_ddb &lt;- DBI::dbConnect(duck(), dbdir = \":memory:\") # Créer une base duckdb virtuelle\nduck_df &lt;- conn_ddb |&gt; tbl(\"path/dataset/**/*.parquet\")\n# Le ** signifie \"tout\", et permet de lire tous les fichiers parquet du dossier\n# Dans un fichier partitionné par exemple"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#connexions-aux-bases-sql",
    "href": "pages/r_usages/usages_connexion.html#connexions-aux-bases-sql",
    "title": "Recueil de données",
    "section": "",
    "text": "Si vous utilisez Rstudio, le moyen le plus simple de se connecter à une source de données est d’utiliser l’onglet Connections, généralement situé en haut à droite, avec votre Environnement. En cliquant sur New connection, une fenêtre apparaît et va automatiquement vous proposer les sources à disposition. \n\n\n\nExemple des connections existantes sur mon poste\n\n\nSi vous avez déjà configuré un DSN contenant vos identifiants, les informations de connection devraient déjà être remplies, vous n’avez plus qu’à cliquer sur “OK”, et le code s’exécutera dans la console. Vous pourrez alors visualiser vos bases dans l’onglet Connections\n\nSinon, vous aurez besoin d’entrer les paramètres suivants :\n\nuser = “…” pour le nom d’utilisateur\npassword = “…” pour le mot de passe\nhost et port si besoin\ndbname pour le nom de la base de données\n\nSi vous utilisez uniquement la console, vous pouvez rentrer directement les paramètres dans dbConnect(), en arguments de la fonction.\nUne fois connecté, on peut requêter ses données avec {dplyr} ou en SQL, en utilisant dbGetQuery()\n\nlibrary(DBI)\nlibrary(odbc)\nconn &lt;- DBI::dbConnect(odbc::odbc()) \"server-name\", database = \"MA_BASE\")\n\n# SQL\nma_table &lt;- DBI::dbGetQuery(conn, \n                            \"SELECT * FROM MA_TABLE\n                            WHERE ...\")\n\n\n# DPLYR\nlibrary(dplyr)\nma_table_2 &lt;- dplyr::tbl(conn, \"MA_TABLE\") %&gt;% # ici, on créé une connexion à la table\n  dplyr::filter(...) %&gt;% # on créé la requête\n  dplyr::collect() # et on collecte le résultat dans R avec collect()\n\nPour interagir avec une base SQL pour autre chose qu’une requête (UPDATE, DROP, …), on peut utiliser la librairie {dbplyr}, un back-end de {dplyr} pour les bases de données, ou utiliser DBI::dbExecute()"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#cloud",
    "href": "pages/r_usages/usages_connexion.html#cloud",
    "title": "Recueil de données",
    "section": "",
    "text": "R dispose de nombreuses librairies pour récupérer des données hébergées sur un serveur cloud. Je n’entrerai pas dans les détails de cette partie, car je n’ai pas encore eu beaucoup l’occasion de pratiquer par moi-même, mais je penserai à la mettre à jour dès que possible. \n\n\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build\n\n\n\n\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R :"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#google-cloud-platform",
    "href": "pages/r_usages/usages_connexion.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#aws",
    "href": "pages/r_usages/usages_connexion.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/r_usages/usages_connexion.html#info",
    "href": "pages/r_usages/usages_connexion.html#info",
    "title": "Recueil de données",
    "section": "Info",
    "text": "Info\nRécemment, {duckplyr}, une librairie intégrant {dplyr} avec le moteur de {duckdb} a rejoint le Tidyverse, signe que Duckdb est perçu comme un outil d’avenir. Lire l’article"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html",
    "href": "pages/r_decouvrir/decouvrir_connections.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#google-cloud-platform",
    "href": "pages/r_decouvrir/decouvrir_connections.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#aws",
    "href": "pages/r_decouvrir/decouvrir_connections.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/liste_decouvrir.html",
    "href": "pages/liste_decouvrir.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#xml",
    "href": "pages/r_decouvrir/decouvrir_connections.html#xml",
    "title": "Recueil de données",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/r_decouvrir/decouvrir_connections.html#json",
    "href": "pages/r_decouvrir/decouvrir_connections.html#json",
    "title": "Recueil de données",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/decouvrir_r.html",
    "href": "pages/decouvrir_r.html",
    "title": "Découvrir R",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\nCette section est encore en travaux !\n\n\n\nPlus d’articles seront bientôt publiés ici\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/projets.html",
    "href": "pages/projets.html",
    "title": "Projets",
    "section": "",
    "text": "Ci-dessous vous pourrez retrouver des outils développés pour des projets professionnels ou personnels. \n\n\n\n\n\n\nCette section est encore en travaux !\n\n\n\nPlus de projets seront bientôt publiés ici\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGestionnaire_projets\n\n\nUn tableau de bord pour les chefs de projets\n\n\n\nFélix Marchais\n\n\nSep 15, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html",
    "href": "pages/decouvrir_r/decouvrir_connections.html",
    "title": "Recueil de données",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#google-cloud-platform",
    "href": "pages/decouvrir_r/decouvrir_connections.html#google-cloud-platform",
    "title": "Recueil de données",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de {googleAuthR}\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#aws",
    "href": "pages/decouvrir_r/decouvrir_connections.html#aws",
    "title": "Recueil de données",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#xml",
    "href": "pages/decouvrir_r/decouvrir_connections.html#xml",
    "title": "Recueil de données",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/decouvrir_r/decouvrir_connections.html#json",
    "href": "pages/decouvrir_r/decouvrir_connections.html#json",
    "title": "Recueil de données",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/tidytuesday/20250914/tidytuesday_20250914.html",
    "href": "pages/tidytuesday/20250914/tidytuesday_20250914.html",
    "title": "Tidytuesday - 2025-09-02",
    "section": "",
    "text": "Source : australian.museum\nCette semaine, le tidytuesday porte sur des données d’observations de grenouilles en Australie, dont l’article est diponible ici \nPour cette première participation, je vais simplement créer une heatmap pour visualiser la densité des observations sur la carte de l’Australie. Pour cela, on aura besoin du package {leaflet} et {leaflet.extras}\nDans un premier temps, on va récupérer les données de la semaine.\n\nlibrary(tidytuesdayR)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(leaflet.extras)\n\ntuesdata &lt;- tt_load(\"2025-09-02\")\n\nfrog_id &lt;- tuesdata$frogID_data\n\nL’étape de transformation de données sera assez simple :\n\nNettoyer les noms de colonnes\nCompter le nombre d’observation pour chaque combinaison de coordonnées\n\n\ndf &lt;- frog_id %&gt;% \n  select(lat = decimalLatitude, \n         lon = decimalLongitude,\n         name = scientificName) %&gt;%\n  group_by(lat, lon) %&gt;%\n  count()\n\nPour le plaisir, je rajouterai les provinces du pays sur la carte. \nEnsuite, il suffit de créer la carte avec `leaflet()`.\n\n# Créer le nom des provinces\naus_provinces &lt;- data.frame(\n  name = c(\"New South Wales\", \"Victoria\", \"Queensland\", \"Western Australia\",\n           \"South Australia\", \"Tasmania\", \"Northern Territory\"),\n  latitude = c(-32, -36.5, -25, -26, -30, -42, -20),\n  longitude = c(151, 145, 148, 117, 137, 147, 131)\n)\n\n\nleaflet(df) %&gt;%\n  addTiles() %&gt;%\n  addHeatmap(\n    lng = ~ lon,\n    lat = ~ lat,\n    intensity = ~ n,\n    blur = 1,\n    max = 10, \n    radius = 15\n  )  %&gt;%\n  addLabelOnlyMarkers(\n    lng = ~ aus_provinces$longitude,\n    lat = ~aus_provinces$latitude,\n    label = ~ aus_provinces$name,\n    labelOptions = labelOptions(noHide = TRUE, direction = 'auto', textOnly = TRUE)\n  )\n\n\n\n\n\nCette carte permet de voir facilement que la côte Ouest a une densité d’observation bien plus importante que le reste du pays, principalement autour de Syndey et Melbourne, avec également un grand nombre d’observations autour de Perth à l’Ouest."
  },
  {
    "objectID": "pages/projets/Gestionnaire_projets.html",
    "href": "pages/projets/Gestionnaire_projets.html",
    "title": "Gestionnaire_projets",
    "section": "",
    "text": "Cette application Shiny a été créée comme un tableau de bord permettant à un chef de projet de suivre l’avancée de différentes études. A partir d’un jeu de données fictif chargé dans l’application, il est possible de suivre le nombre et le détail des projets, ainsi que le calendrier de chaque projet et la charge de travail à venir.\nL’application est disponible ici"
  },
  {
    "objectID": "pages/tidytuesday/20250930/cranes.html",
    "href": "pages/tidytuesday/20250930/cranes.html",
    "title": "Cranes",
    "section": "",
    "text": "Cette semaine, le jeu de données porte sur l’observation de grues (les oiseaux) au lac Hornborgasjön, en Suède, entre 1994 et 2025.\nL’objectif de ma visualisation est de mettre en évidence la saisonnalité des observations ainsi que leur augmentation au fil des ans. L’année la plus récente (2025) est indiquée en blanc.\nLe code pour obtenir ce graphe :\n\n##### SETUP ######\nlibrary(tidytuesdayR)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\nlibrary(grid)\n\n# For months names\nSys.setlocale(\"LC_TIME\", \"English\")\n\n\n\n\n\n##### DATA #####\ntuesdata &lt;- tidytuesdayR::tt_load('2025-09-30')\ncranes &lt;- tuesdata$cranes\n\n\n##### CLEANING ######\nclean_cranes &lt;- cranes %&gt;%\n  mutate(\n    year = year(date),\n    date = as.Date(sprintf(\"2025-%02d-%02d\", month(date), day(date))),\n    month_day = format(date, \"%b-%d\")\n  ) %&gt;%\n  filter(!is.na(date) & !is.na(observations))\n\n# determine the most recent year to highlight it\nlatest_year &lt;- max(clean_cranes$year, na.rm = TRUE)\n\n# Get the \"next\" 10.000 after maximal observation number\ny_limit &lt;- ((max(clean_cranes$observations, na.rm = TRUE) %/% 10000) + 1) * 10000\n\n\n\n\n#####PLOT #####\nclean_cranes %&gt;%\n  ggplot(aes(x = date, y = observations, group = factor(year), color = year)) +\n\n  # light, semi-transparent lines per year\n  geom_line(alpha = 0.35, linewidth = 0.6) +\n\n  # points sized by observation count (smaller range so they don't dominate)\n  geom_point(aes(size = observations), alpha = 0.6, show.legend = FALSE) +\n  scale_size(range = c(0.8, 3.5)) +\n\n  # highlight the most recent year with a bold, bright line and points on top\n  geom_line(\n    data = filter(clean_cranes, year == latest_year),\n    aes(x = date, y = observations, group = factor(year)),\n    color = \"#FFFFFF\",\n    size = 1.2,\n    inherit.aes = FALSE\n  ) +\n  geom_point(\n    data = filter(clean_cranes, year == latest_year),\n    aes(x = date, y = observations),\n    color = \"#FFFFFF\",\n    size = 2,\n    inherit.aes = FALSE\n  ) +\n\n  # continuous color gradient for the year variable using the viridis-like ramp\n   scale_color_viridis_c(guide = guide_colorbar(title = \"Year\", barwidth = unit(6, \"cm\"))) +\n\n  # radial (y) axis - keep the scale available for plotting but don't show the default radial text\n  scale_y_continuous(\n    limits = c(0, y_limit),\n    expand = c(0, 0),\n    breaks = c(0,10000,20000),\n    labels = c(\"0\",\"10k\",\"20k\")\n  ) +\n\n  # show months around the circle\n  scale_x_date(\n    breaks = seq(as.Date(\"2025-01-01\"), as.Date(\"2025-12-01\"), by = \"1 month\"),\n    labels = function(x) format(x, \"%b\"),\n    limits = c(as.Date(\"2025-01-01\"), as.Date(\"2025-12-31\"))\n  ) +\n\n  # polar coordinates with January at top\n  coord_polar(start = -pi/2) +\n\n  # labels\n  labs(\n    title = \"Annual Pattern of Crane Observations\",\n    subtitle = \"Each year mapped onto a single calendar\",\n    caption = \"Data: Tidytuesday | Viz: @fmarchais\",\n    x = NULL,\n    y = NULL\n  ) +\n\n  # revert the earlier radial-label tweak (remove visible radial labels in the margin)\n  theme(\n    panel.background = element_rect(fill = \"#0f1115\", colour = NA),\n    plot.background = element_rect(fill = \"#0f1115\", colour = NA),\n    legend.background = element_rect(fill = \"#0f1115\", colour = NA),\n    legend.key = element_rect(fill = NA, colour = NA),\n    text = element_text(color = \"white\"),\n    plot.title = element_text(size = 12, face = \"bold\", color = \"white\"),\n    plot.subtitle = element_text(size = 9, color = \"grey90\"),\n    plot.caption = element_text(size = 9, color = \"grey70\"),\n\n    # make y & x axis more visible\n    axis.text.y = element_text(color = \"white\", size = 10, margin = margin(r = 6), hjust = 0.5),\n    axis.ticks.y = element_line(color = \"white\", size = 0.5),\n    axis.ticks.length = unit(3, \"pt\"),\n    axis.text.x = element_text(color = \"grey95\", size = 11),\n\n    # remove the \"net\" in the background (radial grid)\n    panel.grid.major.y = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title = element_blank(),\n    plot.margin = margin(10, 10, 10, 10),\n    \n    legend.position = \"bottom\"\n  )\n\n\n# ggsave(filename = \"my_plot.png\", dpi = \"retina\")"
  },
  {
    "objectID": "pages/tidytuesday/20250914/frogs.html",
    "href": "pages/tidytuesday/20250914/frogs.html",
    "title": "Frogs",
    "section": "",
    "text": "Source : australian.museum\nCette semaine, le tidytuesday porte sur des données d’observations de grenouilles en Australie, dont l’article est diponible ici \nPour cette première participation, je vais simplement créer une heatmap pour visualiser la densité des observations sur la carte de l’Australie. Pour cela, on aura besoin du package {leaflet} et {leaflet.extras}\nDans un premier temps, on va récupérer les données de la semaine.\n\nlibrary(tidytuesdayR)\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(leaflet.extras)\n\ntuesdata &lt;- tt_load(\"2025-09-02\")\n\nfrog_id &lt;- tuesdata$frogID_data\n\nL’étape de transformation de données sera assez simple :\n\nNettoyer les noms de colonnes\nCompter le nombre d’observation pour chaque combinaison de coordonnées\n\n\ndf &lt;- frog_id %&gt;% \n  select(lat = decimalLatitude, \n         lon = decimalLongitude,\n         name = scientificName) %&gt;%\n  group_by(lat, lon) %&gt;%\n  count()\n\nPour le plaisir, je rajouterai les provinces du pays sur la carte. \nEnsuite, il suffit de créer la carte avec `leaflet()`.\n\n# Créer le nom des provinces\naus_provinces &lt;- data.frame(\n  name = c(\"New South Wales\", \"Victoria\", \"Queensland\", \"Western Australia\",\n           \"South Australia\", \"Tasmania\", \"Northern Territory\"),\n  latitude = c(-32, -36.5, -25, -26, -30, -42, -20),\n  longitude = c(151, 145, 148, 117, 137, 147, 131)\n)\n\n\nleaflet(df) %&gt;%\n  addTiles() %&gt;%\n  addHeatmap(\n    lng = ~ lon,\n    lat = ~ lat,\n    intensity = ~ n,\n    blur = 1,\n    max = 10, \n    radius = 15\n  )  %&gt;%\n  addLabelOnlyMarkers(\n    lng = ~ aus_provinces$longitude,\n    lat = ~aus_provinces$latitude,\n    label = ~ aus_provinces$name,\n    labelOptions = labelOptions(noHide = TRUE, direction = 'auto', textOnly = TRUE)\n  )\n\n\n\n\n\nCette carte permet de voir facilement que la côte Ouest a une densité d’observation bien plus importante que le reste du pays, principalement autour de Syndey et Melbourne, avec également un grand nombre d’observations autour de Perth à l’Ouest."
  },
  {
    "objectID": "pages/articles/ragnar.html",
    "href": "pages/articles/ragnar.html",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "",
    "text": "Etant plutôt du genre à être dans les derniers à suivre une tendance, mon utilisation des LLM était jusqu’à récemment limitée à poser des questions à chat-GPT ou GitHub Copilot. Il y a environ deux semaines, en discutant avec un ami dont le métier est justement d’accompagner les entreprises dans leur passage à l’IA, celui-ci m’a expliqué les différents mots-clés du domaine : “MCP”, “Agent”, “Contexte” et surtout : la “RAG” (Retrieval-Augmented Generation), ou “Génération Augmentée par Récupération”.\nLa RAG, c’est faire lire des documents à un LLM pour qu’il puisse les utiliser dans ses réponse. Cela revient à ajouter de nouvelles données (que l’on estime fiables) à sa base d’entraînement et permet de le spécialiser dans un domaine.\nCa tombe bien ! Depuis que j’ai commencé à coder, j’utilise Zotero pour indexer des tonnes de guides et d’articles sur R. L’idée m’est immédiatement venue : créer un assistant de code spécialisé en R et en données de santé."
  },
  {
    "objectID": "pages/articles/ragnar.html#récupérer-les-documents",
    "href": "pages/articles/ragnar.html#récupérer-les-documents",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Récupérer les documents",
    "text": "Récupérer les documents\nTout d’abord, commençons par extraire notre bibliothèque Zotero. On aura besoin des PDFs déjà récupérés et des liens vers les documents enregistrés. \nPour les PDFs, dans Zotero allez dans Fichier &gt; Exporter la bibliothèque &gt; Format : “Zotero RDF” et cochez “Exporter les fichiers”. Vous obtiendrez ainsi un dossier “Ma bibliothèque”, qui contient un sous-dossier “files”, qui contient les documents, et un fichier “Ma bibliothèque.rdf” que nous n’utiliserons pas.\nPour obtenir les URLs, exportez simplement votre bibliothèque au format.csv.\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(glue)\nlibrary(ragnar)\nlibrary(rollama)\n\n# Récupérer tous les chemins des fichiers PDF dans le dossier \"files\"\npdf_paths &lt;- list.files(\n  path = \"D:/Ma bibliothèque/files/\",\n   pattern = \"\\\\.pdf\", \n   full.names = TRUE, \n   recursive = TRUE)\n\n# Récupérer les liens dans le fichier .csv\nzotero_csv &lt;- read_csv2(\"D:/ma_biblio_csv.csv\") %&gt;%\n  filter(!is.na(Url) | !is.na(`Link Attachments`) )\n\nzotero_urls &lt;- zotero_csv %&gt;% \n  select(Url, `Link Attachments`) %&gt;%\n  unlist() %&gt;%\n  na.omit() %&gt;%\n  unique()\n\n# Ragnar permet aussi de récupérer les liens présents sur une page.\n# On peut ainsir récupérer toutes les pages d'une documentation \n# à partir du lien principal\nzotero_external_links &lt;- c()\nfor(link in zotero_urls){\n  tryCatch({\n    doc &lt;- ragnar_find_links(link, depth = 2)\n    zotero_external_links &lt;- append(zotero_external_links, doc)\n  })\n}\n  \n# On combine le tout pour obtenir un seul vecteur\nfull_links &lt;- c(pdf_paths, zotero_urls, zotero_external_links) %&gt;% \n  unique()\n\n\n\n\n\n\n\nCaution\n\n\n\nMa bibliothèque compte aujourd’hui près d’un millier de documents, et en considérant une moyenne d’une minute par document, il m’a fallu plus de 30 heures pour tout ingérer. Pour faire cette expérience de votre côté, vous pouvez tester avec seulement la documentation du package {rhino} en remplaçant full_links par ce lien : “https://appsilon.github.io/rhino/articles/tutorial/create-your-first-rhino-app.html”"
  },
  {
    "objectID": "pages/articles/ragnar.html#créer-le-store",
    "href": "pages/articles/ragnar.html#créer-le-store",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Créer le store",
    "text": "Créer le store\nLe store est une base DuckDB qui contiendra nos documents, découpés en chunks, pour permettre à l’assistant d’y accéder.\n\n# Si on ne met que le nom, enregistré sous C:/user/votre_nom/ (sur Windows)\nstore_location &lt;- \"zotero_ragnar.duckdb\"\n\n# Créer le store\nstore &lt;- ragnar_store_create(\n  store_location,\n  embed = \\(x) ragnar::embed_ollama(x, model = \"llama3.2:3b-instruct-q4_K_M\"),\n  overwrite = TRUE\n)\n\n# S'y connecter\nstore &lt;- ragnar_store_connect(\"zotero_ragnar.duckdb\", read_only = FALSE)"
  },
  {
    "objectID": "pages/articles/ragnar.html#ingérer-les-documents-dans-le-store",
    "href": "pages/articles/ragnar.html#ingérer-les-documents-dans-le-store",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Ingérer les documents dans le store",
    "text": "Ingérer les documents dans le store\nMaintenant que le store est créé, on va enregistrer nos documents via une boucle. read_as_markdown permet de transformer le document (URL, PDF ou autre) en markdown, puis markdown_chunk permet de le découper en chunk pour que le LLM puisse l’exploiter.\n\n\n\n\n\n\nCaution\n\n\n\nLorsqu’une URL est fournie, {ragnar} va scraper la page. Certains sites n’autorisent pas le webscraping (et c’est leur droit) et vous renverront une erreur 403. Dans ce cas, il n’y a pas grand chose à faire. On ajoutera un tryCatch() à notre boucle pour ne pas la casser si une erreur est renvoyée.\n\n\n\nfor (path in full_links) {\n  tryCatch({\n    chunks &lt;- path |&gt;\n      read_as_markdown() |&gt;\n      markdown_chunk()\n    \n    ragnar_store_insert(store, chunks)\n    # pour visualiser la progression\n    print(which(path == full_links), \"/\", length(full_links))\n\n  }, error = function(e) {\n    cat(\"Error processing\", path, \":\", e$message, \"\\n\")\n    # Optionally log the error or take other action\n  })\n}\n\n# Indispensable pour rendre notre store exploitable\nragnar_store_build_index(store)\n\n# On peut ensuite vérifier l'intégration des documents avec\nragnar_store_inspect(store)"
  },
  {
    "objectID": "pages/articles/ragnar.html#préparer-lassistant",
    "href": "pages/articles/ragnar.html#préparer-lassistant",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Préparer l’assistant",
    "text": "Préparer l’assistant\nOn va tester notre assistant en lui demander de nous aider à utiliser le framework {rhino}, développé par Appsilon pour aider à créer des applications R/Shiny robustes.\n\n# Notre Query\ntext &lt;- \"How to use the {Rhino} R package to create a Shiny app ? Be concise\"\n\n\n# On peut visualiser les chunks les plus pertinents pour notre question avec\nrelevant_chunks &lt;- ragnar_retrieve(store, text)\n\n\n# Définir un prompt de préparation\n# il sera possible d'enregistrer ce prompt dans un .Rprofile pour ne pas avoir à le répéter\nsystem_prompt &lt;- stringr::str_squish(\n  \"\n  You are an expert R programmer and mentor. You are concise.\n\n  Before responding, retrieve relevant material from the knowledge store. Quote or\n  paraphrase passages, clearly marking your own words versus the source. Provide a\n  working link for every source cited, as well as any additional relevant links.\n  Do not answer unless you have retrieved and cited a source.\n  \"\n)"
  },
  {
    "objectID": "pages/articles/ragnar.html#discuter-avec-lassistant",
    "href": "pages/articles/ragnar.html#discuter-avec-lassistant",
    "title": "Créer un assistant de code personnel avec {ragnar} et Zotero",
    "section": "Discuter avec l’assistant",
    "text": "Discuter avec l’assistant\nOn va tout d’abord tester notre assistant, pour voir s’il connait le package {rhino} :\n\nchat &lt;- ellmer::chat_ollama(\n  system_prompt,\n  model = \"llama3.2:3b-instruct-q4_K_M\"\n)\n\nchat$chat(text)\n\n\n# I'm unable to retrieve accurate information regarding the \"{Rhino}\" R package without more context. However, I can provide general guidance on creating a Shiny app using the Shiny package in R.\n# \n# To start building a Shiny app:\n# \n# 1.  Install and load the `shiny` package:\n# \n# ``` r\n# install.packages(\"shiny\")\n# library(shiny)\n# ....\n\nPour le moment, il est incapable de répondre. \nOn va maintenant lui donner accès au store :\n\nragnar_register_tool_retrieve(chat, store)\nchat$chat(text)\n\n\n\n# ◯ \\[tool call\\] rag_retrieve_from_store_003(text = \" installing and loading shiny package\") ● #\\&gt; \\[{\"origin\":\"https://appsilon.github.io/rhino/articles/tutorial/create-your-first-rhino-app.html\",\"doc_id\":1,\"ch… To create a Shiny app using the Rhino package, follow these steps:\n# \n# 1.  Install Rhino: `package::install(\"rhino\")`\n# 2.  Create an initial Rhino application: `rhino::init(\"RhinoApplication\")`\n# \n# Install necessary packages:\n# \n# ``` r\n# # In R console\n# rhino::pkg_install(c(\n#   \"dplyr\",\n#   \"echarts4r\",\n#   \"htmlwidgets\",\n#   \"reactable\",\n#   \"tidyr\"\n# ))\n# ```\n# .....\n\nVictoire ! Notre assistant connaît désormais {rhino} et peut nous accompagner pour le développement d’applications Shiny plus poussées !\nIl ne reste plus qu’à continuer avec tous les documents de notre bibliothèque pour développer les connaissances de notre assistant.\nNotre modèle étant installé en local, l’assistant fonctionne même sans connection internet, de façon illimitée et gratuite. Si le modèle n’est pas assez performant pour vous, vous pouvez parcourir la liste de modèles Ollama pour en trouver un plus adapté à votre usage.\n\n\n\n\n\n\nTip\n\n\n\n\nPour ajouter de nouveaux documents, on peut créer une nouvelle boucle avec ragnar_store_insert et ragnar_store_build_index(). On passera simplement l’étape ragnar_store_create() pour passer directement à ragnar_store_connect()\nPour que l’assistant soit prêt dès le lancement de notre IDE, on peut enregistrer les étapes suivantes dans un .Rprofile\n\nragnar_store_connect()\nLe system_prompt\nLa création de chat avec ellmer::chat_ollama()"
  },
  {
    "objectID": "pages/articles/connections.html",
    "href": "pages/articles/connections.html",
    "title": "R : un outil à tout faire",
    "section": "",
    "text": "R est un langage qui permet d’intéragir avec à peu près n’importe quel format de données :\nMais pas seulement ! R peut également travailler avec des images (OCRiser un PDF pour récupérer son contenu, ou en générer un), des fichiers DICOM, et bien plus encore."
  },
  {
    "objectID": "pages/articles/connections.html#google-cloud-platform",
    "href": "pages/articles/connections.html#google-cloud-platform",
    "title": "R : un outil à tout faire",
    "section": "Google Cloud Platform",
    "text": "Google Cloud Platform\nVoici une liste non exhaustive des librairies permettant de travailler avec Google Cloud Platform, disponible sur la vignette de googleAuthR\n\ngoogleComputeEngineR - Google Compute Engine VMs API\nsearchConsoleR - Search Console API\nbigQueryR - BigQuery API. Part of the cloudyr project.\ngoogleAnalyticsR - Google Analytics API\ngoogleTagManagerR - Google Tag Manager API by IronistM\ngoogleID - Simple user info from G+ API for Shiny app authentication flows.\ngoogleCloudStorageR - Google Cloud Storage API\nRoogleVision - R Package for Image Recogntion, Object Detection, and OCR using the Google’s Cloud Vision API\ngoogleLanguageR - Access Speech to Text, Entity analysis and translation APIs from R\ngoogleCloudRunner - Continuous Development and Integration with Cloud Run, Cloud Scheduler and Cloud Build"
  },
  {
    "objectID": "pages/articles/connections.html#aws",
    "href": "pages/articles/connections.html#aws",
    "title": "R : un outil à tout faire",
    "section": "AWS",
    "text": "AWS\nLa documentation officielle de Amazon Web Service dispose d’un tutoriel pour accéder aux données du service depuis R."
  },
  {
    "objectID": "pages/articles/connections.html#xml",
    "href": "pages/articles/connections.html#xml",
    "title": "R : un outil à tout faire",
    "section": "XML",
    "text": "XML\nSupposons que nous ayons un fichier “livres.xml” ressemblant à cela :\n\nlibrary(xml2)\n\nxml_doc &lt;- as_xml_document(\n\"&lt;livres&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n    &lt;auteur&gt;Jean Martin&lt;/auteur&gt;\n    &lt;annee&gt;2020&lt;/annee&gt;\n  &lt;/livre&gt;\n  &lt;livre&gt;\n    &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n    &lt;auteur&gt;Marie Dupont&lt;/auteur&gt;\n    &lt;annee&gt;2021&lt;/annee&gt;\n  &lt;/livre&gt;\n&lt;/livres&gt;\"\n)\n\nPour lire le fichier .xml, on utilisera\n\nxml_doc &lt;- xml2::read_xml(\"livres.xml\")\n\nEnsuite, on peut extraire les titres avec\n\ntitres_xml &lt;- xml_find_all(xml_doc, \".//livre/titre\")\nprint(titres_xml)\n\n{xml_nodeset (2)}\n[1] &lt;titre&gt;R pour les débutants&lt;/titre&gt;\n[2] &lt;titre&gt;Analyse de données avec R&lt;/titre&gt;\n\n\nLes fonctions xml_find_*() permettent d’utiliser des expression xpath, similaire à du REGEX mais pour les architectures en arbre et renvoient des objets de classe xml_nodeset. Pour récupérer un vecteur character, on rajoute simplement xml_text()\n\ntitres &lt;- xml_text(titres_xml)\nprint(titres)\n\n[1] \"R pour les débutants\"      \"Analyse de données avec R\""
  },
  {
    "objectID": "pages/articles/connections.html#json",
    "href": "pages/articles/connections.html#json",
    "title": "R : un outil à tout faire",
    "section": "JSON",
    "text": "JSON\nPour lire du JSON, on utilisera simplement fromJSON(), pour convertir une chaîne de texte, ou read_json() pour lire un fichier .json. Les deux fonctions renvoient directement un data.frame\nlibrary(jsonlite)\n\nlivres_json &lt;- fromJSON(\n'\n[\n  {\n    \"titre\": \"R pour les débutants\",\n    \"auteur\": \"Jean Dupont\",\n    \"annee\": 2020\n  },\n  {\n    \"titre\": \"Analyse de données avec R\",\n    \"auteur\": \"Marie Curie\",\n    \"annee\": 2021\n  }\n]\n')\n\nprint(livres_json)\n                  titre      auteur annee\n1 R pour les débutants Jean Dupont 2020 2 Analyse de données avec R Marie Curie 2021\nOn citera aussi la possibilité de convertir un objet R en JSON avec la fonction toJSON()."
  },
  {
    "objectID": "pages/articles.html",
    "href": "pages/articles.html",
    "title": "Articles",
    "section": "",
    "text": "R est un langage de programmation qui semble particulièrement méconnu. On lit régulièrement que c’est un langage “dédié aux statistiques”, qui serait limité par rapport à d’autres langages (au hasard, Python). \nDans cette section, vous trouverez des exemples des différents usages de R et pourquoi il est selon moi un langage parfait pour travailler avec des données.\n\n\n\n\n\n\nCette section est encore en travaux !\n\n\n\nPlus d’articles seront bientôt publiés ici\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nCréer un assistant de code personnel avec {ragnar} et Zotero\n\n\n\nR\n\n\nIA\n\n\nLLM\n\n\n\nComment entraîner un modèle LLM open-source sur des documents pour se faire un assistant de code spécialisé dans son domaine d’expertise\n\n\n\nFélix Marchais\n\n\nOct 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecueil de données\n\n\n\nR\n\n\nBases de données\n\n\n\nSe connecter à tout type de données avec R, en local ou sur le cloud\n\n\n\nFélix Marchais\n\n\nJul 29, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/articles/nettoyage.html",
    "href": "pages/articles/nettoyage.html",
    "title": "Qualification et nettoyage",
    "section": "",
    "text": "Qualification\ndétecter les erreurs : méthode manuelle avec fonctions persos, tidyverse et flextable {validate} {pointblank}\n\n\nNettoyage\nL’une des grandes forces de R est le Tidyverse: un ensemble de packages qui permettent de manipuler les données avec facilité. - {dplyr} Permet de filtrer et sélectionner les données, et regroupe les grandes fonctions de SQL (SELECT, FILTER, DISTINCT, COUNT, UPDATE/mutate()… ) - {stringr} Manipule des chaînes de texte - {lubridate} Manipule des dates et périodes de temps - {tidyr} Aide à créer des données au format tidy : “un individu par ligne, une variable par colonne”\nOn peut aussi citer {cleaner}, un excellent package pour nettoyer ses données \nCi-dessous, un exemple :"
  }
]